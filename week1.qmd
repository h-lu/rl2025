# 第一周：强化学习入门

::: {.callout-tip appearance="simple"}
## 本周学习目标
- 了解什么是强化学习，以及强化学习的核心概念
- 区分强化学习与监督学习、无监督学习
- 了解强化学习在商业领域的应用案例
- 初步体验 AI 辅助编程，并使用 AI 工具进行简单的 Python 编程练习
- 熟悉强化学习常用的 Python 库
:::

## 第一次课：什么是强化学习？

::: {.callout-important}
## 核心定义
强化学习是一种通过与环境交互来学习的机器学习方法。智能体通过不断尝试和犯错来学习最优策略。
:::

### 1. 强化学习的核心概念

::: {.callout-note}
## 以电商推荐系统为例理解核心概念

#### 智能体 (Agent)
- 负责学习和做出决策的实体
- 例如：推荐算法就是一个智能体，它决定向用户推荐什么商品

#### 环境 (Environment)
- 智能体所处的外部世界
- 例如：用户群体、商品库、市场状况等
- 环境会对智能体的动作做出响应

#### 状态 (State)
- 环境在某一时刻的描述
- 例如：用户的历史浏览记录、搜索关键词、当前页面停留时间等
- 智能体根据状态来决定下一步动作

#### 动作 (Action)
- 智能体可以采取的操作
- 例如：推荐特定商品、调整商品展示顺序、发送个性化优惠券等

#### 奖励 (Reward)
- 环境对智能体动作的反馈
- 例如：用户点击推荐商品(正奖励)、直接关闭页面(负奖励)
- 奖励信号指导智能体改进决策
:::

### 2. 机器学习方法对比

::: {.callout-important}
## 学习方法对比
| 特征 | 强化学习 | 监督学习 | 无监督学习 |
|------|----------|----------|------------|
| 学习方式 | 通过交互和尝试 | 从标注数据中学习 | 从数据模式中学习 |
| 数据需求 | 无需标注数据 | 需要大量标注数据 | 无需标注数据 |
| 反馈类型 | 奖励信号(延迟) | 即时准确的标签 | 无直接反馈 |
| 适用场景 | 决策和控制问题 | 分类和回归问题 | 聚类和降维问题 |
:::

### 3. 商业应用案例详解

::: {.callout-note}
## 智能推荐系统
- 应用场景：电商平台、内容平台
- 实现方式：
  - 收集用户行为数据作为状态
  - 推荐算法作为智能体
  - 用户反馈作为奖励信号
- 商业价值：
  - 提高用户转化率
  - 增加平台收入
  - 改善用户体验
:::

::: {.callout-note}
## 动态定价系统
- 应用场景：酒店预订、网约车平台
- 实现方式：
  - 市场供需作为状态
  - 价格调整作为动作
  - 成交量和收入作为奖励
- 商业价值：
  - 优化收入管理
  - 平衡供需关系
  - 提高资源利用率
:::

## 第二次课：AI辅助编程入门与平衡杆实践

### 1. AI辅助编程工具入门

::: {.callout-warning}
## 注意事项
AI辅助编程工具可以显著提高编程效率，但要注意理解生成的代码逻辑
:::

::: {.callout-tip}
## GitHub Copilot 安装步骤
1. 打开 VS Code
2. 转到扩展市场
3. 搜索 "GitHub Copilot"
4. 点击安装
:::

::: {.callout-note}
## 实用技巧
- 使用清晰的注释引导生成
- 分步骤编写复杂逻辑
- 及时检查生成的代码
- 理解并修改不合适的建议
:::

### 2. 强化学习环境搭建

::: {.callout-tip}
## Gymnasium 库基础使用
```python
# 安装 Gymnasium
pip install gymnasium

# 基本使用示例
import gymnasium as gym

# 创建环境
env = gym.make("CartPole-v1", render_mode="human")

# 获取环境信息
print(f"动作空间: {env.action_space}")
print(f"状态空间: {env.observation_space}")
```
:::

::: {.callout-tip}
## Stable Baselines3 库基础使用
```python
# 安装 Stable Baselines3
pip install stable-baselines3

# 基本使用示例
from stable_baselines3 import DQN

# 创建模型
model = DQN("MlpPolicy", env, verbose=1)

# 训练模型
model.learn(total_timesteps=10000)
```
:::

### 3. CartPole 环境实践

::: {.callout-important}
## CartPole 环境说明
CartPole 是强化学习入门的经典环境，目标是通过左右移动小车来保持杆子平衡
:::

::: {.callout-note}
## 环境参数
```python
import gymnasium as gym
import numpy as np

# 创建环境
env = gym.make("CartPole-v1", render_mode="human")

# 环境参数说明
print("状态空间包含4个连续值:")
print("- 小车位置: [-4.8, 4.8]")
print("- 小车速度: [-∞, ∞]")
print("- 杆子角度: [-0.418, 0.418]")
print("- 杆子角速度: [-∞, ∞]")

print("\n动作空间包含2个离散动作:")
print("- 0: 向左推")
print("- 1: 向右推")
```
:::

::: {.callout-tip}
## 随机动作示例代码
```python
# 运行随机策略
observation, info = env.reset()
total_reward = 0

for step in range(100):
    # 随机选择动作
    action = env.action_space.sample()
    
    # 执行动作
    observation, reward, terminated, truncated, info = env.step(action)
    total_reward += reward
    
    # 打印当前状态
    print(f"Step {step}: State = {observation}, Reward = {reward}")
    
    # 判断是否需要重置
    if terminated or truncated:
        print(f"Episode finished after {step + 1} steps")
        print(f"Total reward: {total_reward}")
        break

env.close()
```
:::

::: {.callout-important}
## 课后作业
1. 环境配置
   - 安装 Python 3.8+
   - 配置 VS Code 和 GitHub Copilot
   - 安装所需 Python 库

2. 编程练习
   - 修改随机动作示例，尝试实现简单的规则策略
   - 记录并分析不同策略的表现
   - 使用 AI 辅助工具优化代码

3. 思考题
   - 强化学习如何应用到你的专业领域？
   - CartPole 环境中的状态空间设计有什么特点？
   - 为什么需要重置环境？
:::

::: {.callout-note}
## 预习资料
1. 阅读材料
   - Gymnasium 官方文档
   - Stable Baselines3 入门教程
   - 马尔可夫决策过程基础概念

2. 视频资源
   - CartPole 环境详解
   - 强化学习基础概念讲解

3. 下周预习重点
   - 马尔可夫决策过程
   - 价值函数与策略函数
   - Grid World 环境介绍
:::

