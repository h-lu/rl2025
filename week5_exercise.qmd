---
title: "Week 5 - 学生练习"
---

# 练习目标

*   巩固对时序差分 (TD) 学习核心思想（自举）的理解。
*   掌握 TD(0) 预测算法的更新规则，理解 TD 目标和 TD 误差。
*   练习在具体场景下应用 TD(0) 更新规则。
*   通过对比加深对 TD(0) 和 MC 方法在偏差-方差、适用性等方面差异的理解。
*   练习使用 Gridworld 环境进行实验。

# 练习内容

## 练习 1: TD 概念理解

1.  **自举 (Bootstrapping):** 请用你自己的话解释什么是 TD 学习中的“自举 (Bootstrapping)”。它与 MC 方法不使用自举有何不同？自举带来了哪些优点和缺点？
2.  **TD 目标 vs. MC 目标:**
    *   TD(0) 预测的更新目标 (TD Target) 是什么？（写出表达式）
    *   MC 预测的更新目标是什么？（写出表达式或名称）
    *   两者计算的主要区别是什么？哪个依赖于未来的完整奖励序列？哪个依赖于对未来价值的当前估计？
3.  **TD 误差:** TD 误差 $\delta_t = R_{t+1} + \gamma V(S_{t+1}) - V(S_t)$ 的直观含义是什么？它衡量了什么？

## 练习 2: TD(0) 更新计算

假设我们正在使用 TD(0) 评估一个策略 $\pi$。当前状态 $S$ 的价值估计 $V(S) = 10$。智能体在状态 $S$ 执行某个动作后，观测到奖励 $R = -1$，并转移到下一个状态 $S'$。当前对下一个状态 $S'$ 的价值估计 $V(S') = 12$。假设学习率 $\alpha = 0.1$，折扣因子 $\gamma = 0.9$。

请根据 TD(0) 更新规则计算更新后的 $V(S)$ 的值：
$V(S) \leftarrow V(S) + \alpha [R + \gamma V(S') - V(S)] = ?$

（请写出计算步骤和最终结果）

## 练习 3: TD(0) vs. MC 对比思考

请根据本周所学，思考并回答以下对比问题：

1.  **偏差与方差:** 为什么说 MC 估计是无偏的，而 TD(0) 估计是有偏的？为什么 TD(0) 的方差通常比 MC 低？
2.  **适用任务:** 为什么 TD(0) 可以应用于持续性任务 (Continuing Tasks)，而基本的 MC 方法通常不行？
3.  **收敛速度:** 在实践中，为什么 TD(0) 通常比 MC 收敛更快？（提示：与方差和更新频率有关）
4.  **敏感性:** 为什么 TD(0) 对价值函数的初始值比 MC 更敏感？

## 练习 4: Gridworld TD(0) 实验代码理解 (基于 Lab 3)

本练习基于讲义/Lab 3 中讨论的 Gridworld 环境和 TD(0) 预测。假设你已经有了一个可以运行的 Gridworld 环境和 TD(0) 实现代码（或者参考讲义中的伪代码）。

1.  **核心更新定位:** 请指出 TD(0) 算法实现代码中，计算 TD 目标 (`R + \gamma * V[next_state]`) 和 TD 误差 (`td_target - V[state]`) 的关键代码行。
2.  **学习率 $\alpha$ 的作用:**
    *   如果在实验中将学习率 $\alpha$ 设置得非常大（例如 $\alpha=1.0$ 或更大），你预期会观察到什么现象？为什么？
    *   如果将学习率 $\alpha$ 设置得非常小（例如 $\alpha=0.001$），你预期会观察到什么现象？为什么？
3.  **(思考)** 在 Lab 3 中，我们对比了 TD(0) 和 MC 在 Gridworld 上的表现。请结合你的实验结果（或预期结果）和理论知识，总结一下 TD(0) 相对于 MC 在这个 Gridworld 任务上的主要优势是什么？

# 提交要求

*   请将你的答案整理成一个文档（如 Word, PDF, 或 Markdown 文件）。
*   对于练习 1, 3, 4，请清晰地回答问题并阐述理由。
*   对于练习 2，请写出计算步骤和结果。
*   文件命名格式：`姓名_学号_Week5_Exercise.xxx`。
*   通过教学平台提交。