---
title: "第四周：Q-Learning 算法优化与改进"
---

::: {.callout-tip appearance="simple"}
## 本周学习目标
- 了解 Q-Learning 算法的局限性，例如状态空间爆炸问题
- 掌握 ε-greedy 策略等探索策略，提升智能体的探索能力
- 学习 Q-Table 初始化、奖励函数设计等实用技巧
- 学习使用调试工具和 AI 工具，解决编程问题
- 通过小组项目一的实践，巩固算法的理解和应用
:::

## 第一次课：Q-Learning 算法优化与改进

::: {.callout-important}
## Q-Learning 算法的局限性

### 状态空间爆炸问题
- 状态空间过大时，Q-Table 规模庞大
- 连续状态空间需要离散化处理
- 存储和计算成本高

### 探索-利用困境
- 需要平衡探索新动作和利用已知最优动作
- $\epsilon$-greedy 策略探索效率较低
- 可能浪费时间在无用区域

### 收敛性问题
- 需要满足特定条件才能收敛
- 环境可能不满足 MDP 假设
- 可能收敛到局部最优解

### 超参数敏感性
- 性能受超参数影响大
- 需要经验和技巧调整
- 调整过程耗时耗力
:::

::: {.callout-note}
## 探索策略详解

### $\epsilon$-greedy 策略
- 以 $\epsilon$ 概率随机探索
- 以 $1-\epsilon$ 概率选择最优动作
- 简单但探索效率低

### $\epsilon$-greedy 退火策略
- 训练初期增加探索（大 $\epsilon$）
- 训练后期减少探索（小 $\epsilon$）
- 线性或指数衰减方式

### 高级探索策略
- UCB 算法：考虑动作不确定性
- Thompson Sampling：概率采样
- Softmax 策略：基于 Q 值分布
:::

::: {.callout-warning}
## Q-Table 初始化技巧

### 零值初始化
- 简单易实现
- 可能导致初始探索不足
- 收敛速度较慢

### 随机值初始化
- 鼓励初始探索
- 打破对称性
- 需谨慎选择范围

### 乐观初始化
- 初始化为较大值
- 鼓励探索未知动作
- 适用于稀疏奖励环境

### 基于领域知识
- 利用先验知识
- 加速学习过程
- 通用性较差
:::

::: {.callout-tip}
## 奖励函数设计原则

### 基本原则
- 与任务目标一致
- 考虑稀疏vs密集奖励
- 注意奖励尺度

### 奖励类型
1. **稀疏奖励**
   - 只在目标状态给予奖励
   - 更符合真实场景
   - 学习难度大

2. **密集奖励**
   - 提供中间过程奖励
   - 加速学习过程
   - 需要careful设计

### 示例（迷宫寻宝）
```python
# 稀疏奖励
rewards = {
    'goal': 10,      # 到达宝藏
    'trap': -10,     # 陷阱
    'default': 0     # 其他状态
}

# 密集奖励
rewards = {
    'goal': 10,      # 到达宝藏
    'trap': -10,     # 陷阱
    'step': -0.1,    # 每步惩罚
    'distance': lambda d: 1/d  # 距离奖励
}
```
:::

## 第二次课：小组项目实践

::: {.callout-important}
## 项目优化方向

### 算法优化
- 实现退火探索策略
- 优化 Q-Table 初始化
- 改进奖励函数设计

### 代码优化
- 提高运行效率
- 使用 NumPy 向量化
- 添加可视化功能

### 性能优化
- 系统调整超参数
- 记录实验结果
- 分析优化效果
:::

::: {.callout-note}
## 调试技巧

### 基本工具
- print 语句跟踪
- pdb 调试器使用
- 日志记录分析

### AI 辅助
- 使用 GitHub Copilot
- 代码自动补全
- 错误快速定位

### 问题解决
- 环境代码检查
- 算法逻辑验证
- 超参数调整
- 奖励设计分析
:::

::: {.callout-warning}
## 课后作业
1. 继续优化项目代码
2. 准备项目报告
3. 预习下周内容：
   - Double Q-Learning
   - Experience Replay
   - 深度强化学习基础
:::

::: {.callout-tip}
## 下周预习重点
1. 项目报告准备
2. 答辩 PPT 制作
3. Sarsa 算法学习
4. 深度强化学习入门
:::
