<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Week 3: 最优决策与 Bellman 最优方程 – 智能计算</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./week4_lecture.html" rel="next">
<link href="./week2_lecture.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css" integrity="sha512-1ycn6IcaQQ40/MKBW2W4Rhis/DbILU74C1vSrLJxCq57o941Ym01SwNsOMqvEBFlcgUa6xkm/sYwpb+ilR5gUw==" crossorigin="anonymous" referrerpolicy="no-referrer">

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="styles/custom.css">
</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./week1_lecture.html">讲义</a></li><li class="breadcrumb-item"><a href="./week3_lecture.html"><span class="chapter-title">Week 3: 最优决策与 Bellman 最优方程</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">智能计算</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">课程介绍</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">讲义</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week1_lecture.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Week 1: 商业决策智能化与强化学习概览</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week2_lecture.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Week 2: 序贯决策建模 - 马尔可夫决策过程 (MDP)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week3_lecture.html" class="sidebar-item-text sidebar-link active"><span class="chapter-title">Week 3: 最优决策与 Bellman 最优方程</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week4_lecture.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Week 4: 蒙特卡洛方法 - 从完整经验中学习</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week5_lecture.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Week 5: 时序差分学习 - 从不完整经验中学习</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week6_lecture.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Week 6: 同策略控制 - SARSA</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week7_lecture.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Week 7: 异策略控制 - Q-Learning (重点)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./sarsa_vs_qlearning_comparison.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">SARSA 与 Q-Learning 算法详解与探索策略对比</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week8_lecture.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Week 8: Q-Learning 应用讨论与中期回顾</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week9_lecture.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Week 9: 函数逼近入门</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week10_lecture.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Week 10: 深度 Q 网络 (DQN)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week10_lab_dqn_experiment.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Week 10 综合实验：DQN 强化学习综合实践</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week11_lecture.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Week 11: 策略梯度方法 (Policy Gradient Methods)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week12_lecture.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Week 12: Actor-Critic 方法</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week13_lecture.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Week 13: 商业案例分析 1 - 动态定价与资源优化</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week14_lecture.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Week 14: 商业案例分析 2 - 个性化推荐与营销</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week15_lecture.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Week 15: 实践挑战、伦理规范与项目指导</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week16_lecture.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Week 16: 课程总结与未来展望</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">练习</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week1_exercise.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Week 1 - 学生练习</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week2_exercise.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Week 2 - 学生练习</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week3_exercise.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Week 3 - 学生练习</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week4_exercise.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Week 4 - 学生练习</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week5_exercise.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Week 5 - 学生练习</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week6_exercise.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Week 6 - 学生练习</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week7_exercise.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Week 7 - 学生练习</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week8_exercise.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Week 8 - 学生练习</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week9_exercise.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Week 9 - 学生练习</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week10_exercise.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Week 10 - 学生练习</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week11_exercise.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Week 11 - 学生练习</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week12_exercise.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Week 12 - 学生练习</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week13_exercise.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Week 13 - 学生练习</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week14_exercise.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Week 14 - 学生练习</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week15_exercise.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Week 15 - 学生练习</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week16_exercise.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Week 16 - 学生练习</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#回顾mdp-与-bellman-期望方程" id="toc-回顾mdp-与-bellman-期望方程" class="nav-link active" data-scroll-target="#回顾mdp-与-bellman-期望方程">回顾：MDP 与 Bellman 期望方程</a></li>
  <li><a href="#最优价值函数-optimal-value-functions" id="toc-最优价值函数-optimal-value-functions" class="nav-link" data-scroll-target="#最优价值函数-optimal-value-functions">最优价值函数 (Optimal Value Functions)</a></li>
  <li><a href="#bellman-最优方程-bellman-optimality-equation" id="toc-bellman-最优方程-bellman-optimality-equation" class="nav-link" data-scroll-target="#bellman-最优方程-bellman-optimality-equation">Bellman 最优方程 (Bellman Optimality Equation)</a>
  <ul class="collapse">
  <li><a href="#最优方程的作用" id="toc-最优方程的作用" class="nav-link" data-scroll-target="#最优方程的作用">最优方程的作用</a></li>
  <li><a href="#实际应用中的选择" id="toc-实际应用中的选择" class="nav-link" data-scroll-target="#实际应用中的选择">实际应用中的选择</a></li>
  <li><a href="#理解最优的含义" id="toc-理解最优的含义" class="nav-link" data-scroll-target="#理解最优的含义">理解“最优”的含义</a></li>
  </ul></li>
  <li><a href="#lab-1-热身-熟悉-gymgymnasium-环境" id="toc-lab-1-热身-熟悉-gymgymnasium-环境" class="nav-link" data-scroll-target="#lab-1-热身-熟悉-gymgymnasium-环境">Lab 1 (热身): 熟悉 Gym/Gymnasium 环境</a>
  <ul class="collapse">
  <li><a href="#目标" id="toc-目标" class="nav-link" data-scroll-target="#目标">目标</a></li>
  <li><a href="#步骤" id="toc-步骤" class="nav-link" data-scroll-target="#步骤">步骤</a></li>
  <li><a href="#提交要求" id="toc-提交要求" class="nav-link" data-scroll-target="#提交要求">提交要求</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./week1_lecture.html">讲义</a></li><li class="breadcrumb-item"><a href="./week3_lecture.html"><span class="chapter-title">Week 3: 最优决策与 Bellman 最优方程</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span class="chapter-title">Week 3: 最优决策与 Bellman 最优方程</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="回顾mdp-与-bellman-期望方程" class="level1">
<h1>回顾：MDP 与 Bellman 期望方程</h1>
<p>上周我们学习了：</p>
<ul>
<li><strong>马尔可夫决策过程 (MDP):</strong> <span class="math inline">\((S, A, P, R, \gamma)\)</span> 作为序贯决策问题的形式化框架。</li>
<li><strong>马尔可夫性质:</strong> 未来只取决于现在。</li>
<li><strong>回报 (Return)</strong> <span class="math inline">\(G_t:\)</span> 未来折扣奖励的总和。</li>
<li><strong>策略 (Policy)</strong> <span class="math inline">\(\pi:\)</span> 状态到动作的映射。</li>
<li><strong>价值函数</strong> (<span class="math inline">\(V_{\pi}, Q_{\pi}\)</span>): 衡量在策略 <span class="math inline">\(\pi\)</span> 下状态或状态-动作对的长期价值。</li>
<li><strong>Bellman 期望方程:</strong> 建立了当前状态价值与后继状态价值之间的递归关系，用于<strong>评估 (Evaluation)</strong> 一个给定的策略 <span class="math inline">\(\pi\)</span>。</li>
</ul>
<p><span class="math display">\[
\begin{aligned}
V_{\pi}(s) &amp;= \sum_{a \in A} \pi(a|s) \sum_{s' \in S} P(s'|s,a) [R(s,a,s') + \gamma V_{\pi}(s')] \\
Q_{\pi}(s,a) &amp;= \sum_{s' \in S} P(s'|s,a) [R(s,a,s') + \gamma V_{\pi}(s')]
\end{aligned}
\]</span></p>
<p>今天，我们的目标是找到<strong>最优 (Optimal)</strong> 的决策策略。</p>
</section>
<section id="最优价值函数-optimal-value-functions" class="level1">
<h1>最优价值函数 (Optimal Value Functions)</h1>
<p>在所有可能的策略中，至少存在一个策略比其他所有策略都好或者一样好。这个（些）策略称为<strong>最优策略 (Optimal Policy)</strong>，记作 <span class="math inline">\(\pi^*\)</span>。</p>
<div class="callout callout-style-default callout-important callout-titled" title="一定存在最优策略吗？">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
一定存在最优策略吗？
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>是的，在有限 MDP 中，至少存在一个最优策略。这是因为：</p>
<ol type="1">
<li><strong>有限性保证</strong>：状态空间 <span class="math inline">\(S\)</span> 和动作空间 <span class="math inline">\(A\)</span> 都是有限的，策略空间也是有限的。</li>
<li><strong>价值函数有界</strong>：由于折扣因子 <span class="math inline">\(\gamma &lt; 1\)</span>，价值函数 <span class="math inline">\(V_{\pi}(s)\)</span> 对于任何策略 <span class="math inline">\(\pi\)</span> 都是有界的。</li>
<li><strong>存在性定理</strong>：根据 MDP 理论，在有限 MDP 中，存在至少一个确定性策略 <span class="math inline">\(\pi^*\)</span>，使得对于所有状态 <span class="math inline">\(s \in S\)</span>，<span class="math inline">\(V_{\pi^*}(s) \geq V_{\pi}(s)\)</span> 对所有其他策略 <span class="math inline">\(\pi\)</span> 成立。</li>
</ol>
<p>需要注意的是：</p>
<ul>
<li>可能存在多个最优策略，但它们都共享相同的最优价值函数 <span class="math inline">\(V^*\)</span> 和 <span class="math inline">\(Q^*\)</span>。</li>
<li>在无限 MDP 中，最优策略的存在性需要额外的条件保证。</li>
</ul>
<p><strong>示例 1：库存管理</strong></p>
<ul>
<li>状态空间 S：当前库存水平（离散或连续）</li>
<li>动作空间 A：订购数量（离散或连续）</li>
<li>奖励 R：销售收入 - 订购成本 - 库存持有成本 - 缺货惩罚</li>
<li>最优策略 π*：在每种库存水平下选择最优的订购数量，以最大化长期利润</li>
<li>V*(s)：在库存水平 s 下，采用最优策略所能获得的最大预期利润</li>
<li>Q*(s,a)：在库存水平 s 下，采取订购数量 a 后继续采用最优策略所能获得的最大预期利润</li>
<li><strong>存在最优策略的原因：</strong>
<ul>
<li>状态空间和动作空间都是有限的（即使连续，在实际应用中也会离散化处理）</li>
<li>奖励函数有界（销售收入和成本都是有限的）</li>
<li>折扣因子 γ &lt; 1 保证了长期利润的收敛性</li>
</ul></li>
</ul>
<p><strong>示例 2：广告投放</strong></p>
<ul>
<li>状态空间 S：用户特征（如年龄、性别、浏览历史）</li>
<li>动作空间 A：投放的广告类型</li>
<li>奖励 R：用户点击广告带来的收入</li>
<li>最优策略 π*：针对不同用户特征选择最优的广告类型，以最大化长期点击收入</li>
<li>V*(s)：对于具有特征 s 的用户，采用最优策略所能获得的最大预期收入</li>
<li>Q*(s,a)：对于具有特征 s 的用户，投放广告类型 a 后继续采用最优策略所能获得的最大预期收入</li>
<li><strong>存在最优策略的原因：</strong>
<ul>
<li>用户特征和广告类型都是有限的</li>
<li>每次点击带来的收入是有限的</li>
<li>折扣因子 γ &lt; 1 保证了长期收入的收敛性</li>
<li>用户行为模式相对稳定，满足马尔可夫性质</li>
</ul></li>
</ul>
<p><strong>示例 3：机器人路径规划</strong></p>
<ul>
<li>状态空间 S：机器人的当前位置</li>
<li>动作空间 A：可移动的方向（上、下、左、右）</li>
<li>奖励 R：到达目标位置获得正奖励，撞墙获得负奖励</li>
<li>最优策略 π*：在每个位置选择最优的移动方向，以最快到达目标</li>
<li>V*(s)：在位置 s 下，采用最优策略所能获得的最大预期奖励</li>
<li>Q*(s,a)：在位置 s 下，采取动作 a 后继续采用最优策略所能获得的最大预期奖励</li>
<li><strong>存在最优策略的原因：</strong>
<ul>
<li>地图大小有限，位置状态是有限的</li>
<li>动作空间是离散且有限的</li>
<li>奖励函数有界（正负奖励都是有限的）</li>
<li>环境动态是确定性的，满足马尔可夫性质</li>
</ul></li>
</ul>
</div>
</div>
</div>
<div class="callout callout-style-default callout-warning callout-titled" title="不存在最优策略的情况">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
不存在最优策略的情况
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>在某些情况下，MDP 可能不存在最优策略，常见原因包括：</p>
<ol type="1">
<li><strong>无限状态/动作空间且无界奖励</strong>
<ul>
<li>当状态空间或动作空间是无限的，且奖励函数无界时，价值函数可能发散，导致不存在最优策略。</li>
<li>示例：连续状态和动作空间中的某些控制问题，如果奖励随状态/动作无限增长。</li>
</ul></li>
<li><strong>部分可观测性 (POMDP)</strong>
<ul>
<li>在部分可观测马尔可夫决策过程中，智能体无法直接观察完整状态，可能导致不存在确定性的最优策略。</li>
<li>示例：机器人导航中，传感器只能提供部分环境信息。</li>
</ul></li>
<li><strong>非平稳环境</strong>
<ul>
<li>当环境动态（转移概率或奖励函数）随时间变化时，可能不存在固定的最优策略。</li>
<li>示例：金融市场中的交易策略，市场条件不断变化。</li>
</ul></li>
<li><strong>多目标冲突</strong>
<ul>
<li>当存在多个相互冲突的目标时，可能不存在单一的最优策略。</li>
<li>示例：同时优化利润和客户满意度的商业决策。</li>
</ul></li>
<li><strong>不可终止的 MDP</strong>
<ul>
<li>在某些无限期 MDP 中，如果折扣因子 γ=1，价值函数可能发散。</li>
<li>示例：某些持续进行的控制任务，没有明确的终止状态。</li>
</ul></li>
<li><strong>不满足马尔可夫性质</strong>
<ul>
<li>当当前状态不能完全捕获历史信息时，MDP 假设不成立。</li>
<li>示例：某些需要记忆历史状态才能做出最优决策的场景。</li>
</ul></li>
</ol>
</div>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled" title="思考：围棋是否存在最优策略？">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
思考：围棋是否存在最优策略？
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>围棋作为一种完全信息博弈，理论上存在最优策略，但实际中难以实现：</p>
<ol type="1">
<li><strong>理论层面：</strong>
<ul>
<li>围棋是有限状态、有限动作的完全信息博弈</li>
<li>根据Zermelo定理，存在确定性的最优策略</li>
<li>先手或后手必有一方有必胜策略（或双方都有保证和局的策略）</li>
</ul></li>
<li><strong>实践层面：</strong>
<ul>
<li>状态空间极其庞大（约 10^170 种可能局面）</li>
<li>无法通过穷举法找到最优策略</li>
<li>即使使用强化学习（如 AlphaGo），也只能逼近最优策略</li>
</ul></li>
<li><strong>现实意义：</strong>
<ul>
<li>当前 AI 水平已远超人类，但尚未达到理论最优</li>
<li>证明最优策略的存在性 ≠ 能够实际找到它</li>
<li>在可预见的未来，围棋仍将是一个极具挑战性的问题</li>
</ul></li>
</ol>
<p><strong>启示：</strong></p>
<ul>
<li>理论最优与实际可行之间存在巨大鸿沟</li>
<li>在复杂商业决策中，追求”足够好”的策略往往比寻找理论最优更实际</li>
<li>强化学习等 AI 方法可以帮助我们在复杂问题中逼近最优解</li>
</ul>
</div>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled" title="哪些棋类游戏找到了最优策略？">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
哪些棋类游戏找到了最优策略？
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>虽然大多数棋类游戏过于复杂而无法找到实际的最优策略，但一些简单的棋类游戏已经被完全解决：</p>
<ol type="1">
<li><strong>井字棋 (Tic-Tac-Toe)</strong>
<ul>
<li>已被完全解决，最优策略下双方必和</li>
<li>先手如果完美执行策略，永远不会输</li>
<li>后手如果完美执行策略，至少可以保证和局</li>
</ul></li>
<li><strong>五子棋 (Gomoku)</strong>
<ul>
<li>在15x15棋盘上，先手有必胜策略</li>
<li>1993年由Victor Allis证明 [Allis, 1994]</li>
<li>但实际找到具体的最优策略仍然非常困难</li>
</ul></li>
<li><strong>国际象棋残局 (Chess Endgames)</strong>
<ul>
<li>某些简单的残局（如王对王+兵）已被完全解决</li>
<li>通过穷举法建立了残局数据库 [Thompson, 1986]</li>
<li>但完整国际象棋的最优策略尚未找到</li>
</ul></li>
<li><strong>跳棋 (Checkers)</strong>
<ul>
<li>2007年被完全解决</li>
<li>由Jonathan Schaeffer团队通过穷举法证明 [Schaeffer et al., 2007]</li>
<li>最优策略下双方必和</li>
</ul></li>
<li><strong>四子棋 (Connect Four)</strong>
<ul>
<li>1988年被完全解决</li>
<li>先手有必胜策略</li>
<li>通过穷举法证明 [Allis, 1988]</li>
</ul></li>
</ol>
<p><strong>主要参考文献：</strong></p>
<ul>
<li>Allis, L. V. (1994). Searching for solutions in games and artificial intelligence. PhD thesis, University of Limburg, Maastricht.</li>
<li>Thompson, K. (1986). Retrograde analysis of certain endgames. ICCA Journal, 9(3), 131-139.</li>
<li>Schaeffer, J., Burch, N., Björnsson, Y., Kishimoto, A., Müller, M., Lake, R., … &amp; Sutphen, S. (2007). Checkers is solved. Science, 317(5844), 1518-1522.</li>
<li>Allis, L. V. (1988). A knowledge-based approach of connect-four. Master’s thesis, Vrije Universiteit, Amsterdam.</li>
</ul>
<p><strong>启示：</strong></p>
<ul>
<li>简单棋类游戏可以通过穷举法找到最优策略</li>
<li>随着游戏复杂度增加，找到最优策略变得极其困难</li>
<li>即使理论上存在最优策略，实际找到它可能需要巨大的计算资源</li>
<li>在复杂游戏中，AI方法（如强化学习）可以帮助我们逼近最优策略</li>
</ul>
</div>
</div>
</div>
<p>最优策略对应的价值函数称为<strong>最优价值函数 (Optimal Value Functions)</strong>。</p>
<ul>
<li><strong>最优状态值函数 (Optimal State-Value Function, <span class="math inline">\(V^*\)</span>):</strong>
<ul>
<li>定义: <span class="math inline">\(V^*(s) = \max_{\pi} V_{\pi}(s)\)</span> for all <span class="math inline">\(s \in S\)</span></li>
<li>含义: 对于状态 <span class="math inline">\(s\)</span>，在所有可能的策略中能够获得的最大预期回报。它代表了状态 <span class="math inline">\(s\)</span> 的<strong>真正内在价值</strong>。</li>
</ul></li>
<li><strong>最优动作值函数 (Optimal Action-Value Function, <span class="math inline">\(Q^*\)</span>):</strong>
<ul>
<li>定义: <span class="math inline">\(Q^*(s, a) = \max_{\pi} Q_{\pi}(s, a)\)</span> for all <span class="math inline">\(s \in S, a \in A\)</span></li>
<li>含义: 对于状态 <span class="math inline">\(s\)</span> 和动作 <span class="math inline">\(a\)</span>，在所有可能的策略下，先执行动作 <span class="math inline">\(a\)</span> 然后继续遵循该策略所能获得的最大预期回报。它代表了在状态 <span class="math inline">\(s\)</span> 下采取动作 <span class="math inline">\(a\)</span> 的<strong>真正最优价值</strong>。</li>
</ul></li>
</ul>
<div class="callout callout-style-default callout-important callout-titled" title="Q* 的重要性">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Q* 的重要性
</div>
</div>
<div class="callout-body-container callout-body">
<p>如果我们知道了 <span class="math inline">\(Q^*(s, a)\)</span>，那么找到最优策略 <span class="math inline">\(\pi^*\)</span> 就非常简单：在任何状态 <span class="math inline">\(s\)</span>，只需选择那个使得 <span class="math inline">\(Q^*(s, a)\)</span> 最大的动作 <span class="math inline">\(a\)</span> 即可。 <span class="math inline">\(\pi^*(s) = \arg\max_a Q^*(s, a)\)</span> 这是一个<strong>贪心策略 (Greedy Policy)</strong>。相对于最优动作值函数 <span class="math inline">\(Q^*\)</span> 采取贪心策略，本身就是最优策略。</p>
<p>如何理解这个结论在随机性环境中的适用性：</p>
<ol type="1">
<li><span class="math inline">\(Q^*(s, a)\)</span> 已经包含了状态转移的不确定性，它表示的是在状态 <span class="math inline">\(s\)</span> 采取动作 <span class="math inline">\(a\)</span> 后的<strong>期望</strong>累积回报</li>
<li>在随机性环境中，虽然每次执行相同动作可能导致不同的结果，但 <span class="math inline">\(Q^*(s, a)\)</span> 已经对这些可能结果进行了加权平均</li>
<li>因此，选择最大 <span class="math inline">\(Q^*(s, a)\)</span> 的动作是在长期期望意义下的最优选择，即使单次执行可能不是最优结果</li>
<li>这种策略在多次执行中会表现出最优性，因为它最大化的是期望回报，而不是单次回报</li>
</ol>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled" title="V* 与 Q* 的关系">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
V* 与 Q* 的关系
</div>
</div>
<div class="callout-body-container callout-body">
<p><span class="math inline">\(V^*\)</span> 和 <span class="math inline">\(Q^*\)</span> 之间有以下重要关系：</p>
<ul>
<li><span class="math inline">\(V^*(s) = \max_a Q^*(s, a)\)</span>
<ul>
<li>这是根据最优价值函数的定义直接得到的</li>
<li>表示一个状态的最优价值等于在该状态下采取最优动作的价值</li>
</ul></li>
<li><span class="math inline">\(Q^*(s, a) = \sum_{s' \in S} P(s' | s, a) [R(s, a, s') + \gamma \max_{a'} Q^*(s', a')]\)</span>
<ul>
<li>这是 Bellman 最优方程的直接结果</li>
<li>表示在状态 s 采取动作 a 的最优价值等于：
<ol type="1">
<li>即时奖励 R(s, a, s’)</li>
<li>加上所有可能的后继状态采取最优动作的价值的折扣期望</li>
</ol></li>
</ul></li>
</ul>
</div>
</div>
</section>
<section id="bellman-最优方程-bellman-optimality-equation" class="level1">
<h1>Bellman 最优方程 (Bellman Optimality Equation)</h1>
<p>Bellman 最优方程描述了最优价值函数 <span class="math inline">\(V^*\)</span> 和 <span class="math inline">\(Q^*\)</span> 必须满足的条件。它与 Bellman 期望方程不同，期望方程是针对某个特定策略 <span class="math inline">\(\pi\)</span> 的，而最优方程是针对最优策略 <span class="math inline">\(\pi^*\)</span> 的，并且隐含了<strong>最大化</strong>操作。</p>
<p><strong><span class="math inline">\(V^*\)</span> 的 Bellman 最优方程:</strong></p>
<p><span class="math display">\[
\begin{align}
V^*(s) &amp;= \max_a E [R_{t+1} + \gamma V^*(S_{t+1}) | S_t=s, A_t=a] \\
      &amp;= \max_a \sum_{s' \in S} P(s' | s, a) [R(s, a, s') + \gamma V^*(s')]
\end{align}
\]</span></p>
<p><strong>直观解读:</strong></p>
<p>一个状态 <span class="math inline">\(s\)</span> 的<strong>最优价值 (<span class="math inline">\(V^*(s)\)</span>)</strong> 等于：选择那个能够最大化 <strong>(即时奖励 + 未来最优预期价值)</strong> 的动作 <span class="math inline">\(a\)</span> 所带来的期望回报。 这个 <span class="math inline">\(\max_a\)</span> 体现了最优策略在每个状态下都会选择最好的动作。</p>
<p><strong><span class="math inline">\(Q^*\)</span> 的 Bellman 最优方程:</strong></p>
<p><span class="math display">\[
\begin{align}
Q^*(s, a) &amp;= E [R_{t+1} + \gamma \max_{a'} Q^*(S_{t+1}, a') | S_t=s, A_t=a] \\
         &amp;= \sum_{s' \in S} P(s' | s, a) [R(s, a, s') + \gamma \max_{a'} Q^*(s', a')] \\
         &amp;= \sum_{s' \in S} P(s' | s, a) [R(s, a, s') + \gamma V^*(s')]
\end{align}
\]</span></p>
<p>(利用 V* 和 Q* 的关系)</p>
<p><strong>直观解读:</strong></p>
<p>在状态 <span class="math inline">\(s\)</span> 采取动作 <span class="math inline">\(a\)</span> 的<strong>最优价值 (<span class="math inline">\(Q^*(s, a)\)</span>)</strong> 等于：</p>
<ol type="1">
<li>获得即时奖励 <span class="math inline">\(R(s, a, s')\)</span>。</li>
<li>转移到后继状态 <span class="math inline">\(s'\)</span>。</li>
<li>在后继状态 <span class="math inline">\(s'\)</span>，采取<strong>最优</strong>的下一个动作 <span class="math inline">\(a'\)</span> (即 <span class="math inline">\(\max_{a'} Q^*(s', a')\)</span>，这等价于 <span class="math inline">\(V^*(s')\)</span>)。</li>
<li>将即时奖励和后继状态的最优折扣价值加起来，并对所有可能的后继状态 <span class="math inline">\(s'\)</span> 求期望。</li>
</ol>
<div class="callout callout-style-default callout-note callout-titled" title="期望方程 vs. 最优方程">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
期望方程 vs.&nbsp;最优方程
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><strong>Bellman 期望方程:</strong> 用于<strong>评估</strong>一个给定的策略 <span class="math inline">\(\pi\)</span>，计算 <span class="math inline">\(V_{\pi}\)</span> 或 <span class="math inline">\(Q_{\pi}\)</span>。它是一个线性方程组（如果状态动作空间有限）。</li>
<li><strong>Bellman 最优方程:</strong> 用于描述<strong>最优</strong>价值函数 <span class="math inline">\(V^*\)</span> 或 <span class="math inline">\(Q^*\)</span> 满足的条件。由于 <code>max</code> 操作的存在，它是一个非线性方程组。求解这个方程组就能得到最优价值函数，进而得到最优策略。</li>
</ul>
</div>
</div>
<section id="最优方程的作用" class="level2">
<h2 class="anchored" data-anchor-id="最优方程的作用">最优方程的作用</h2>
<p>Bellman 最优方程在强化学习中扮演着至关重要的角色，主要体现在以下几个方面：</p>
<ol type="1">
<li><p><strong>理论基石:</strong> 为强化学习算法提供了坚实的理论基础，证明了最优价值函数和最优策略的存在性。</p></li>
<li><p><strong>算法设计指导:</strong> 许多经典强化学习算法（如值迭代、策略迭代、Q-learning）都是基于 Bellman 最优方程设计的。</p></li>
<li><p><strong>最优策略求解:</strong> 通过求解 Bellman 最优方程，可以直接得到最优价值函数 <span class="math inline">\(V^*\)</span> 和 <span class="math inline">\(Q^*\)</span>，进而推导出最优策略 <span class="math inline">\(\pi^*\)</span>。</p></li>
<li><p><strong>收敛性保证:</strong> 在满足一定条件下，基于 Bellman 最优方程的算法能够保证收敛到最优解。</p></li>
<li><p><strong>价值函数更新:</strong> 为价值函数的更新提供了明确的数学公式，指导智能体如何根据经验改进其价值估计。</p></li>
<li><p><strong>策略改进:</strong> 通过比较当前策略与最优价值函数，可以系统地改进策略，使其逐步接近最优。</p></li>
<li><p><strong>理论分析工具:</strong> 可用于分析强化学习算法的收敛速度、样本复杂度等理论性质。</p></li>
<li><p><strong>实际应用指导:</strong> 为实际应用中的策略优化提供了明确的方向，帮助设计更有效的学习算法。</p></li>
</ol>
<div class="callout callout-style-default callout-note callout-titled" title="最优方程 vs. 期望方程">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
最优方程 vs.&nbsp;期望方程
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><strong>最优方程</strong>用于寻找最优策略，包含最大化操作，是非线性方程</li>
<li><strong>期望方程</strong>用于评估特定策略，是线性方程</li>
<li>两者都基于 Bellman 方程，但目标不同</li>
</ul>
</div>
</div>
</section>
<section id="实际应用中的选择" class="level2">
<h2 class="anchored" data-anchor-id="实际应用中的选择">实际应用中的选择</h2>
<p>在实际应用中，我们通常需要根据具体问题和计算资源在期望方程和最优方程之间做出选择：</p>
<ol type="1">
<li><strong>期望方程的应用场景:</strong>
<ul>
<li>当我们需要评估某个特定策略的性能时</li>
<li>在策略迭代算法中，用于策略评估阶段</li>
<li>当状态空间较大时，作为近似求解的起点</li>
<li>在在线学习中，用于实时更新策略价值</li>
</ul></li>
<li><strong>最优方程的应用场景:</strong>
<ul>
<li>当我们的目标是找到最优策略时</li>
<li>在值迭代算法中，直接用于寻找最优价值函数</li>
<li>在Q-learning等off-policy算法中，用于更新最优动作值函数</li>
<li>当计算资源充足时，用于精确求解</li>
</ul></li>
<li><strong>实际考虑因素:</strong>
<ul>
<li><strong>计算复杂度:</strong> 最优方程由于包含max操作，通常比期望方程更难求解</li>
<li><strong>状态空间大小:</strong> 对于大规模问题，通常需要结合近似方法</li>
<li><strong>收敛速度:</strong> 期望方程有时可以更快收敛，但可能陷入次优解</li>
<li><strong>应用需求:</strong> 如果只需要一个可行的好策略，期望方程可能就足够了</li>
</ul></li>
</ol>
<div class="callout callout-style-default callout-tip callout-titled" title="实际应用建议">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
实际应用建议
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>对于小规模问题，可以直接求解最优方程</li>
<li>对于大规模问题，建议采用近似方法或结合使用两种方程</li>
<li>在策略迭代中交替使用两种方程往往能取得较好效果</li>
<li>考虑使用函数逼近等方法来降低计算复杂度</li>
</ul>
</div>
</div>
<ol start="4" type="1">
<li><strong>折中方案:</strong>
<ul>
<li>使用期望方程作为初始近似，逐步向最优方程过渡</li>
<li>在策略迭代中交替使用期望方程和最优方程</li>
<li>采用近似方法（如函数逼近）来降低最优方程的求解难度</li>
</ul></li>
</ol>
<div class="callout callout-style-default callout-warning callout-titled" title="注意事项">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
注意事项
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>虽然 Bellman 最优方程在理论上非常强大，但在实际应用中，由于状态空间可能非常大或连续，直接求解往往不可行</li>
<li>奖励函数的设计会显著影响最优策略的质量</li>
<li>在实际应用中，通常需要在最优性和计算效率之间进行权衡</li>
</ul>
</div>
</div>
</section>
<section id="理解最优的含义" class="level2">
<h2 class="anchored" data-anchor-id="理解最优的含义">理解“最优”的含义</h2>
<ul>
<li><strong>最大化预期累积折扣回报:</strong> 最优策略旨在最大化从任何状态开始的长期期望回报 <span class="math inline">\(G_t\)</span>。</li>
<li><strong>不一定是单步最优:</strong> 最优策略有时可能需要采取一个即时奖励较低的动作，以便进入一个更有利的未来状态，从而获得更高的长期回报（“牺牲小我，完成大我”）。</li>
<li><strong>可能存在多个最优策略:</strong> 对于同一个 MDP，可能存在多个不同的策略都能达到相同的最优价值函数 <span class="math inline">\(V^*\)</span> 和 <span class="math inline">\(Q^*\)</span>。</li>
<li><strong>依赖于 MDP 定义:</strong> 最优性是相对于给定的状态空间 <span class="math inline">\(S\)</span>、动作空间 <span class="math inline">\(A\)</span>、转移概率 <span class="math inline">\(P\)</span>、奖励函数 <span class="math inline">\(R\)</span> 和折扣因子 <span class="math inline">\(\gamma\)</span> 而言的。改变其中任何一个，最优策略和价值函数都可能改变。</li>
</ul>
<div class="callout callout-style-default callout-warning callout-titled" title="奖励设计的关键性">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
奖励设计的关键性
</div>
</div>
<div class="callout-body-container callout-body">
<p>奖励函数 <span class="math inline">\(R\)</span> 直接定义了智能体的目标。如果奖励函数设计不当（例如，只奖励短期行为而忽略长期后果），即使找到了该奖励函数下的“最优”策略，也可能无法实现真正的商业目标。设计一个能够准确反映长期商业价值的奖励函数是 RL 应用中的核心挑战。</p>
</div>
</div>
</section>
</section>
<section id="lab-1-热身-熟悉-gymgymnasium-环境" class="level1">
<h1>Lab 1 (热身): 熟悉 Gym/Gymnasium 环境</h1>
<p>本周的实验课旨在让大家动手实践，熟悉强化学习实验的基本流程和工具。</p>
<section id="目标" class="level2">
<h2 class="anchored" data-anchor-id="目标">目标</h2>
<ol type="1">
<li><strong>安装并配置 Gym/Gymnasium 环境:</strong> 确保大家都能成功运行基本的 Gym 脚本。</li>
<li><strong>理解环境交互循环:</strong> 掌握 <code>reset</code>, <code>step</code>, <code>render</code> 等核心函数的使用。</li>
<li>**观察 <span class="math inline">\(S, A, R:\)</span> 运行一个简单的随机策略智能体，观察状态、动作、奖励的变化。</li>
<li><strong>概念练习:</strong> 将一个简单的商业场景映射到 Gym 环境的要素。</li>
</ol>
</section>
<section id="步骤" class="level2">
<h2 class="anchored" data-anchor-id="步骤">步骤</h2>
<ol type="1">
<li><p><strong>环境安装检查:</strong></p>
<ul>
<li>确保你已经按照上周讲义的指导，在虚拟环境中安装了 <code>gymnasium</code> 和 <code>gymnasium[classic_control]</code>。</li>
<li>尝试运行上周提供的 CartPole 随机智能体示例代码，确保能看到可视化窗口并且代码正常运行。</li>
</ul></li>
<li><p><strong>运行随机智能体:</strong></p>
<ul>
<li>仔细阅读 CartPole 示例代码。</li>
<li>尝试修改代码：
<ul>
<li>改变 <code>range(1000)</code> 中的数字，看看一个回合能持续多少步。</li>
<li>去掉 <code>time.sleep(1)</code>，观察运行速度。</li>
<li>尝试另一个简单的环境，如 “MountainCar-v0” 或 “Acrobot-v1” (如果已安装 <code>box2d-py</code>，可以尝试 “LunarLander-v2”)。观察它们的状态空间、动作空间和奖励结构有何不同。</li>
</ul>
<div class="sourceCode" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> gymnasium <span class="im">as</span> gym</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="co"># env = gym.make("MountainCar-v0", render_mode="human")</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="co"># env = gym.make("Acrobot-v1", render_mode="human")</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="co"># env = gym.make("LunarLander-v2", render_mode="human") # 需要 box2d</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="co"># ... (其余代码类似 CartPole)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
<li><strong>思考:</strong> 随机策略在这些环境中的表现如何？为什么？</li>
</ul></li>
<li><p><strong>理解环境交互循环:</strong></p>
<ul>
<li>在 <code>step</code> 函数前后打印 <code>observation</code>, <code>action</code>, <code>reward</code>, <code>terminated</code>, <code>truncated</code> 的值。</li>
<li>理解 <code>terminated</code> 和 <code>truncated</code> 的区别：
<ul>
<li><code>terminated</code>: 环境达到了自然的终点（成功或失败）。</li>
<li><code>truncated</code>: 环境因为外部限制（如时间步数）而提前结束。</li>
</ul></li>
<li>查看 <code>env.observation_space</code> 和 <code>env.action_space</code>，了解状态和动作的类型与范围。</li>
</ul></li>
<li><p><strong>练习：定义简单商业场景为 Gym 环境 (概念或简化代码)</strong></p>
<p>选择一个简单的商业场景，例如：</p>
<ul>
<li><strong>单商品库存管理:</strong>
<ul>
<li>目标：决定每天订购多少商品以最大化利润。</li>
<li><strong>状态 (<span class="math inline">\(S\)</span>):</strong> 当前库存水平 (离散或连续？)。可以简化为几个等级，如 [低, 中, 高]。</li>
<li><strong>动作 (<span class="math inline">\(A\)</span>):</strong> 订购数量 (离散？)。可以简化为 [不订购, 订购少量, 订购大量]。</li>
<li><strong>奖励 (<span class="math inline">\(R\)</span>):</strong> (销售收入) - (订购成本) - (库存持有成本) - (缺货惩罚)。如何量化这些值？</li>
<li><strong>转移概率 (<span class="math inline">\(P\)</span>):</strong> 假设已知每天的需求概率分布。根据当前库存、订购量和实际需求，计算下一天的库存水平。</li>
<li><strong>折扣因子 (<span class="math inline">\(\gamma\)</span>):</strong> 如何选择？取决于关注短期利润还是长期稳定？</li>
</ul></li>
<li><strong>简单广告投放:</strong>
<ul>
<li>目标：决定在哪个渠道投放广告以最大化点击率或转化率。</li>
<li><strong>状态 (<span class="math inline">\(S\)</span>):</strong> 可以简化为当前日期是工作日还是周末？或者用户的某个简单分类？</li>
<li><strong>动作 (<span class="math inline">\(A\)</span>):</strong> 选择渠道 A 或渠道 B。</li>
<li><strong>奖励 (<span class="math inline">\(R\)</span>):</strong> 该渠道带来的点击次数或转化价值。</li>
<li><strong>转移概率 (<span class="math inline">\(P\)</span>):</strong> 状态转移可能很简单（如第二天），或者依赖于用户行为。</li>
<li><strong>折扣因子 (<span class="math inline">\(\gamma\)</span>):</strong> 如果只关心单次投放效果，<span class="math inline">\(\gamma\)</span> 可以为 0。如果考虑长期影响，<span class="math inline">\(\gamma &gt; 0\)</span>。</li>
</ul></li>
</ul>
<p><strong>任务:</strong></p>
<ul>
<li>选择一个场景。</li>
<li><strong>概念设计:</strong> 清晰地定义 <span class="math inline">\(S, A, R, P\)</span> (可以描述性地说明转移逻辑), <span class="math inline">\(\gamma\)</span>。</li>
<li><strong>(可选) 简化代码框架:</strong> 尝试编写一个 Python 类，模仿 Gym 环境的接口 (<code>__init__</code>, <code>reset</code>, <code>step</code>)。不需要完全实现复杂的逻辑，重点是定义接口和数据结构。</li>
</ul>
<div class="sourceCode" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> gymnasium <span class="im">as</span> gym</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> gymnasium <span class="im">import</span> spaces</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> SimpleInventoryEnv(gym.Env):</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>    metadata <span class="op">=</span> {<span class="st">'render_modes'</span>: [], <span class="st">'render_fps'</span>: <span class="dv">4</span>} <span class="co"># 元数据</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, max_inventory<span class="op">=</span><span class="dv">20</span>, max_order<span class="op">=</span><span class="dv">5</span>, demand_dist<span class="op">=</span>[<span class="fl">0.1</span>, <span class="fl">0.6</span>, <span class="fl">0.3</span>]):</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>() <span class="co"># 调用父类构造函数</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.max_inventory <span class="op">=</span> max_inventory</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.max_order <span class="op">=</span> max_order</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.demand_dist <span class="op">=</span> demand_dist <span class="co"># 假设需求是 0, 1, 2 的概率</span></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.possible_demands <span class="op">=</span> np.arange(<span class="bu">len</span>(demand_dist))</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 定义状态空间：库存水平 (0 到 max_inventory)</span></span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.observation_space <span class="op">=</span> spaces.Discrete(max_inventory <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 定义动作空间：订购数量 (0 到 max_order)</span></span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.action_space <span class="op">=</span> spaces.Discrete(max_order <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 内部状态变量</span></span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>._current_inventory <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _get_obs(<span class="va">self</span>):</span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>._current_inventory</span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _get_info(<span class="va">self</span>):</span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 可以返回一些辅助信息，例如实际需求量</span></span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a>        <span class="co"># return {"demand": self._last_demand}</span></span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> {}</span>
<span id="cb2-32"><a href="#cb2-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-33"><a href="#cb2-33" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> reset(<span class="va">self</span>, seed<span class="op">=</span><span class="va">None</span>, options<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb2-34"><a href="#cb2-34" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().reset(seed<span class="op">=</span>seed) <span class="co"># 处理随机种子</span></span>
<span id="cb2-35"><a href="#cb2-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-36"><a href="#cb2-36" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 重置库存为 0 (或其他初始值)</span></span>
<span id="cb2-37"><a href="#cb2-37" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>._current_inventory <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb2-38"><a href="#cb2-38" aria-hidden="true" tabindex="-1"></a>        observation <span class="op">=</span> <span class="va">self</span>._get_obs()</span>
<span id="cb2-39"><a href="#cb2-39" aria-hidden="true" tabindex="-1"></a>        info <span class="op">=</span> <span class="va">self</span>._get_info()</span>
<span id="cb2-40"><a href="#cb2-40" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> observation, info</span>
<span id="cb2-41"><a href="#cb2-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-42"><a href="#cb2-42" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> step(<span class="va">self</span>, action):</span>
<span id="cb2-43"><a href="#cb2-43" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 1. 获取订购量 (动作)</span></span>
<span id="cb2-44"><a href="#cb2-44" aria-hidden="true" tabindex="-1"></a>        order_quantity <span class="op">=</span> action</span>
<span id="cb2-45"><a href="#cb2-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-46"><a href="#cb2-46" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 2. 计算订购后的库存 (假设立即到货)</span></span>
<span id="cb2-47"><a href="#cb2-47" aria-hidden="true" tabindex="-1"></a>        inventory_after_order <span class="op">=</span> <span class="va">self</span>._current_inventory <span class="op">+</span> order_quantity</span>
<span id="cb2-48"><a href="#cb2-48" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 限制最大库存</span></span>
<span id="cb2-49"><a href="#cb2-49" aria-hidden="true" tabindex="-1"></a>        inventory_after_order <span class="op">=</span> <span class="bu">min</span>(inventory_after_order, <span class="va">self</span>.max_inventory)</span>
<span id="cb2-50"><a href="#cb2-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-51"><a href="#cb2-51" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 3. 模拟随机需求</span></span>
<span id="cb2-52"><a href="#cb2-52" aria-hidden="true" tabindex="-1"></a>        demand <span class="op">=</span> <span class="va">self</span>.np_random.choice(<span class="va">self</span>.possible_demands, p<span class="op">=</span><span class="va">self</span>.demand_dist)</span>
<span id="cb2-53"><a href="#cb2-53" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>._last_demand <span class="op">=</span> demand <span class="co"># 记录需求，可选</span></span>
<span id="cb2-54"><a href="#cb2-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-55"><a href="#cb2-55" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 4. 计算满足的需求 (销售量)</span></span>
<span id="cb2-56"><a href="#cb2-56" aria-hidden="true" tabindex="-1"></a>        sales <span class="op">=</span> <span class="bu">min</span>(inventory_after_order, demand)</span>
<span id="cb2-57"><a href="#cb2-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-58"><a href="#cb2-58" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 5. 计算下一时刻的库存</span></span>
<span id="cb2-59"><a href="#cb2-59" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>._current_inventory <span class="op">=</span> inventory_after_order <span class="op">-</span> sales</span>
<span id="cb2-60"><a href="#cb2-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-61"><a href="#cb2-61" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 6. 计算奖励 (简化示例)</span></span>
<span id="cb2-62"><a href="#cb2-62" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 假设：售价=10, 订购成本=3, 持有成本=1, 缺货惩罚=2</span></span>
<span id="cb2-63"><a href="#cb2-63" aria-hidden="true" tabindex="-1"></a>        revenue <span class="op">=</span> sales <span class="op">*</span> <span class="dv">10</span></span>
<span id="cb2-64"><a href="#cb2-64" aria-hidden="true" tabindex="-1"></a>        order_cost <span class="op">=</span> order_quantity <span class="op">*</span> <span class="dv">3</span></span>
<span id="cb2-65"><a href="#cb2-65" aria-hidden="true" tabindex="-1"></a>        holding_cost <span class="op">=</span> <span class="va">self</span>._current_inventory <span class="op">*</span> <span class="dv">1</span> <span class="co"># 期末库存持有成本</span></span>
<span id="cb2-66"><a href="#cb2-66" aria-hidden="true" tabindex="-1"></a>        shortage_cost <span class="op">=</span> <span class="bu">max</span>(<span class="dv">0</span>, demand <span class="op">-</span> inventory_after_order) <span class="op">*</span> <span class="dv">2</span> <span class="co"># 缺货成本</span></span>
<span id="cb2-67"><a href="#cb2-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-68"><a href="#cb2-68" aria-hidden="true" tabindex="-1"></a>        reward <span class="op">=</span> revenue <span class="op">-</span> order_cost <span class="op">-</span> holding_cost <span class="op">-</span> shortage_cost</span>
<span id="cb2-69"><a href="#cb2-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-70"><a href="#cb2-70" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 7. 确定是否结束 (在这个简单模型中，可以假设永不结束)</span></span>
<span id="cb2-71"><a href="#cb2-71" aria-hidden="true" tabindex="-1"></a>        terminated <span class="op">=</span> <span class="va">False</span></span>
<span id="cb2-72"><a href="#cb2-72" aria-hidden="true" tabindex="-1"></a>        truncated <span class="op">=</span> <span class="va">False</span> <span class="co"># 也可以设置最大步数</span></span>
<span id="cb2-73"><a href="#cb2-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-74"><a href="#cb2-74" aria-hidden="true" tabindex="-1"></a>        observation <span class="op">=</span> <span class="va">self</span>._get_obs()</span>
<span id="cb2-75"><a href="#cb2-75" aria-hidden="true" tabindex="-1"></a>        info <span class="op">=</span> <span class="va">self</span>._get_info()</span>
<span id="cb2-76"><a href="#cb2-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-77"><a href="#cb2-77" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> observation, reward, terminated, truncated, info</span>
<span id="cb2-78"><a href="#cb2-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-79"><a href="#cb2-79" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> render(<span class="va">self</span>):</span>
<span id="cb2-80"><a href="#cb2-80" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 这个简单环境不需要可视化</span></span>
<span id="cb2-81"><a href="#cb2-81" aria-hidden="true" tabindex="-1"></a>        <span class="cf">pass</span></span>
<span id="cb2-82"><a href="#cb2-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-83"><a href="#cb2-83" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> close(<span class="va">self</span>):</span>
<span id="cb2-84"><a href="#cb2-84" aria-hidden="true" tabindex="-1"></a>        <span class="cf">pass</span></span>
<span id="cb2-85"><a href="#cb2-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-86"><a href="#cb2-86" aria-hidden="true" tabindex="-1"></a><span class="co"># --- 如何使用 ---</span></span>
<span id="cb2-87"><a href="#cb2-87" aria-hidden="true" tabindex="-1"></a><span class="co"># env = SimpleInventoryEnv()</span></span>
<span id="cb2-88"><a href="#cb2-88" aria-hidden="true" tabindex="-1"></a><span class="co"># observation, info = env.reset()</span></span>
<span id="cb2-89"><a href="#cb2-89" aria-hidden="true" tabindex="-1"></a><span class="co"># for _ in range(100):</span></span>
<span id="cb2-90"><a href="#cb2-90" aria-hidden="true" tabindex="-1"></a><span class="co">#    action = env.action_space.sample() # 随机选择订购量</span></span>
<span id="cb2-91"><a href="#cb2-91" aria-hidden="true" tabindex="-1"></a><span class="co">#    observation, reward, terminated, truncated, info = env.step(action)</span></span>
<span id="cb2-92"><a href="#cb2-92" aria-hidden="true" tabindex="-1"></a><span class="co">#    print(f"Inv: {observation}, Action: {action}, Reward: {reward}")</span></span>
<span id="cb2-93"><a href="#cb2-93" aria-hidden="true" tabindex="-1"></a><span class="co">#    if terminated or truncated:</span></span>
<span id="cb2-94"><a href="#cb2-94" aria-hidden="true" tabindex="-1"></a><span class="co">#        break</span></span>
<span id="cb2-95"><a href="#cb2-95" aria-hidden="true" tabindex="-1"></a><span class="co"># env.close()</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
</ol>
</section>
<section id="提交要求" class="level2">
<h2 class="anchored" data-anchor-id="提交要求">提交要求</h2>
<ul>
<li>确保你的 Python 环境可以运行 Gym/Gymnasium 示例。</li>
<li>完成商业场景的概念设计 (<span class="math inline">\(S, A, R, P, \gamma\)</span>)。</li>
<li>(可选) 提交你尝试编写的简化 Gym 环境代码框架。</li>
<li><strong>思考:</strong> 在你设计的商业场景中，马尔可夫性质是否容易满足？状态需要包含哪些信息才能更好地近似它？</li>
</ul>
<hr>
<p><strong>下周预告:</strong> 开始学习无模型预测方法 - 蒙特卡洛 (Monte Carlo) 方法。</p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./week2_lecture.html" class="pagination-link" aria-label="Week 2: 序贯决策建模 - 马尔可夫决策过程 (MDP)">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-title">Week 2: 序贯决策建模 - 马尔可夫决策过程 (MDP)</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./week4_lecture.html" class="pagination-link" aria-label="Week 4: 蒙特卡洛方法 - 从完整经验中学习">
        <span class="nav-page-text"><span class="chapter-title">Week 4: 蒙特卡洛方法 - 从完整经验中学习</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>